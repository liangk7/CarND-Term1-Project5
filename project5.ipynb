{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Vehicle Detection Project**\n",
    "\n",
    "**The goals / steps of this project are the following:**\n",
    "\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector.\n",
    "* Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "* Data handling and visualization\n",
    "* Image processing\n",
    "* Video processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Data handling and visualization\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Image processing\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split # sklearn version 0.19.0\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from textwrap import wrap\n",
    "\n",
    "# Video processing\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(u'\\u2713', 'libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images\n",
    "* Import data (visualize sample car/noncar images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import paths\n",
    "path_imgIn = 'test_images/'\n",
    "path_vidIn = 'test_videos/'\n",
    "    \n",
    "# Export paths\n",
    "path_imgOut = 'output_images1/'\n",
    "path_vidOut = 'output_videos1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import car/noncar data\n",
    "\n",
    "# Image paths\n",
    "path_dataCars = '../CarND-Vehicle-Detection/vehicles/'\n",
    "path_dataNoncars = '../CarND-Vehicle-Detection/non-vehicles/'\n",
    "# Create lists to store image paths\n",
    "data_cars = glob.glob(path_dataCars + '**/*.png')\n",
    "data_noncars = glob.glob(path_dataNoncars + '**/*.png')\n",
    "n_cars = len(data_cars)\n",
    "n_noncars = len(data_noncars)\n",
    "\n",
    "print(u'\\u2713', 'images imported')\n",
    "print('Car data size: ', n_cars, ' samples')\n",
    "print('Non-car data size: ', n_noncars, ' samples')\n",
    "\n",
    "# Visualize some of the data\n",
    "n_row = 4\n",
    "n_col = 8\n",
    "f, axs = plt.subplots(n_row, n_col, figsize=(16, 8))\n",
    "f.subplots_adjust(hspace=.2, wspace=.01)\n",
    "axs = axs.ravel()\n",
    "# Car data\n",
    "for i in np.arange((n_row * n_col) // 2):\n",
    "    img = cv2.imread(data_cars[np.random.randint(0, n_cars)])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set_title('car')\n",
    "for i in np.arange((n_row * n_col) // 2, (n_row * n_col)):\n",
    "    img = cv2.imread(data_noncars[np.random.randint(0, n_noncars)])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set_title('not car')\n",
    "    \n",
    "f.savefig(path_imgOut + 'fig1_classData.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Oriented Gradients (HOG)\n",
    "* Get HOG features of image (visualize on sample car/noncar images)\n",
    "* Determine good HOG parameters for processing images\n",
    "* Feature extraction to generate Training/Testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  transform_sqrt=False,\n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient,\n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                       transform_sqrt=False,\n",
    "                       visualise=False, feature_vector=feature_vec)\n",
    "        return features\n",
    "    \n",
    "print(u'\\u2713', 'get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform HOG on sample images of car and noncar\n",
    "car_img = mpimg.imread(data_cars[np.random.randint(n_cars)])\n",
    "_, car_hog = get_hog_features(car_img[:,:,2], 9, 8, 8, vis=True, feature_vec=True)\n",
    "noncar_img = mpimg.imread(data_noncars[np.random.randint(n_noncars)])\n",
    "_, noncar_hog = get_hog_features(noncar_img[:,:,2], 9, 8, 8, vis=True, feature_vec=True)\n",
    "\n",
    "# Visualize comparison between raw image and HOG\n",
    "f, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "axs = axs.ravel()\n",
    "axs[0].axis('off')\n",
    "axs[0].imshow(car_img)\n",
    "axs[0].set_title('Car Sample', fontsize=20)\n",
    "axs[1].axis('off')\n",
    "axs[1].imshow(car_hog, cmap='gray')\n",
    "axs[1].set_title('Car HOG', fontsize=20)\n",
    "axs[2].axis('off')\n",
    "axs[2].imshow(noncar_img)\n",
    "axs[2].set_title('Non-Car Sample', fontsize=20)\n",
    "axs[3].axis('off')\n",
    "axs[3].imshow(noncar_hog, cmap='gray')\n",
    "axs[3].set_title('Non-Car HOG', fontsize=20)\n",
    "\n",
    "print(u'\\u2713', 'HOG examples successfully created')\n",
    "f.savefig(path_imgOut + 'fig2.1_HOG.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function tht can convert color channels\n",
    "def convert_color(img, cspace='RGB'):\n",
    "    if cspace !='RGB':\n",
    "        if cspace == 'HSV':\n",
    "            img_out = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif cspace == 'LUV':\n",
    "            img_out = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif cspace == 'HLS':\n",
    "            img_out = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif cspace == 'YUV':\n",
    "            img_out = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif cspace == 'YCrCb':\n",
    "            img_out = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else:\n",
    "        img_out = np.copy(img)\n",
    "    return img_out\n",
    "\n",
    "print(u'\\u2713', \"convert_color(img, cspace='RGB')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start trying out HOG on different colorspaces\n",
    "color_space = ['RGB', 'HSV', 'LUV', 'HLS', 'YUV', 'YCrCb']\n",
    "n = len(color_space)\n",
    "\n",
    "# Compare color spaces\n",
    "i_car = np.random.randint(n_cars)\n",
    "i_noncar = np.random.randint(n_noncars)\n",
    "car_img = cv2.imread(data_cars[i_car])\n",
    "car_img = cv2.cvtColor(car_img, cv2.COLOR_BGR2RGB)\n",
    "noncar_img = cv2.imread(data_noncars[i_noncar])\n",
    "noncar_img = cv2.cvtColor(noncar_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "f1, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "axs = axs.ravel()\n",
    "axs[0].axis('off')\n",
    "axs[0].imshow(car_img)\n",
    "axs[0].set_title('Car Sample', fontsize=20)\n",
    "axs[1].axis('off')\n",
    "axs[1].imshow(noncar_img)\n",
    "axs[1].set_title('Non-Car Sample', fontsize=20)\n",
    "\n",
    "f1.savefig(path_imgOut + 'fig2.2-1_HOGsample.png')\n",
    "\n",
    "f2, axs = plt.subplots(n, 6, figsize=(12, n*3))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in np.arange(n):\n",
    "    car_img = convert_color(car_img, color_space[i])\n",
    "    _, car_hog0 = get_hog_features(car_img[:,:,0], 9, 8, 8, vis=True, feature_vec=True)\n",
    "    _, car_hog1 = get_hog_features(car_img[:,:,1], 9, 8, 8, vis=True, feature_vec=True)\n",
    "    _, car_hog2 = get_hog_features(car_img[:,:,2], 9, 8, 8, vis=True, feature_vec=True)\n",
    "    noncar_img = convert_color(noncar_img, color_space[i])\n",
    "    _, noncar_hog0 = get_hog_features(noncar_img[:,:,0], 9, 8, 8, vis=True, feature_vec=True)\n",
    "    _, noncar_hog1 = get_hog_features(noncar_img[:,:,1], 9, 8, 8, vis=True, feature_vec=True)\n",
    "    _, noncar_hog2 = get_hog_features(noncar_img[:,:,2], 9, 8, 8, vis=True, feature_vec=True)\n",
    "\n",
    "    for j in range(6):\n",
    "        axs[6*i+j].axis('off')\n",
    "        axs[6*i+j].set_title(\"\\n\".join(wrap(color_space[i] + ', '+ re.findall('[A-Z][^A-Z]*', color_space[i])[j%3] + ' channel', 12)))\n",
    "    axs[6*i+0].imshow(car_hog0, cmap='gray')\n",
    "    axs[6*i+1].imshow(car_hog1, cmap='gray')\n",
    "    axs[6*i+2].imshow(car_hog2, cmap='gray')\n",
    "    axs[6*i+3].imshow(noncar_hog0, cmap='gray')\n",
    "    axs[6*i+4].imshow(noncar_hog1, cmap='gray')\n",
    "    axs[6*i+5].imshow(noncar_hog2, cmap='gray')\n",
    "    \n",
    "f2.savefig(path_imgOut + 'fig2.2-2_HOGcspace.png')\n",
    "\n",
    "print(u'\\u2713', 'colorspace HOGs visualized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems like YUV performs well, so let's use it for future HOG feature extraction\n",
    "color_space = 'YUV'\n",
    "# Next, try different numbers of orientations\n",
    "orient = [4, 8, 12, 16]\n",
    "n = len(orient)\n",
    "\n",
    "# Compare color spaces\n",
    "i_car = np.random.randint(n_cars)\n",
    "i_noncar = np.random.randint(n_noncars)\n",
    "car_img = cv2.imread(data_cars[i_car])\n",
    "car_img = cv2.cvtColor(car_img, cv2.COLOR_BGR2RGB)\n",
    "noncar_img = cv2.imread(data_noncars[i_noncar])\n",
    "noncar_img = cv2.cvtColor(noncar_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "f1, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "axs = axs.ravel()\n",
    "axs[0].axis('off')\n",
    "axs[0].imshow(car_img)\n",
    "axs[0].set_title('Car Sample', fontsize=20)\n",
    "axs[1].axis('off')\n",
    "axs[1].imshow(noncar_img)\n",
    "axs[1].set_title('Non-Car Sample', fontsize=20)\n",
    "\n",
    "f1.savefig(path_imgOut + 'fig2.3-1_HOGsample.png')\n",
    "\n",
    "f2, axs = plt.subplots(n, 6, figsize=(12, n*3))\n",
    "axs = axs.ravel()\n",
    "for i in np.arange(n):\n",
    "    car_img = convert_color(car_img, color_space)\n",
    "    _, car_hog0 = get_hog_features(car_img[:,:,0], orient[i], 8, 8, vis=True, feature_vec=True)\n",
    "    _, car_hog1 = get_hog_features(car_img[:,:,1], orient[i], 8, 8, vis=True, feature_vec=True)\n",
    "    _, car_hog2 = get_hog_features(car_img[:,:,2], orient[i], 8, 8, vis=True, feature_vec=True)\n",
    "    noncar_img = convert_color(noncar_img, color_space)\n",
    "    _, noncar_hog0 = get_hog_features(noncar_img[:,:,0], orient[i], 8, 8, vis=True, feature_vec=True)\n",
    "    _, noncar_hog1 = get_hog_features(noncar_img[:,:,1], orient[i], 8, 8, vis=True, feature_vec=True)\n",
    "    _, noncar_hog2 = get_hog_features(noncar_img[:,:,2], orient[i], 8, 8, vis=True, feature_vec=True)\n",
    "\n",
    "    for j in range(6):\n",
    "        axs[6*i+j].axis('off')\n",
    "        axs[6*i+j].set_title(\"\\n\".join(wrap(color_space + ', '+ re.findall('[A-Z][^A-Z]*', color_space)[j%3] + ' channel, ' + str(orient[i]) + ' orientations', 12)))\n",
    "    axs[6*i+0].imshow(car_hog0, cmap='gray')\n",
    "    axs[6*i+1].imshow(car_hog1, cmap='gray')\n",
    "    axs[6*i+2].imshow(car_hog2, cmap='gray')\n",
    "    axs[6*i+3].imshow(noncar_hog0, cmap='gray')\n",
    "    axs[6*i+4].imshow(noncar_hog1, cmap='gray')\n",
    "    axs[6*i+5].imshow(noncar_hog2, cmap='gray')\n",
    "    \n",
    "f2.savefig(path_imgOut + 'fig2.3-1_HOGorient.png')\n",
    "\n",
    "print(u'\\u2713', 'orientations visualized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems like 12 has sufficient performance, so set orient=12 for future HOG feature extractions\n",
    "orient = 12\n",
    "# Next, let's try the pixels per cell\n",
    "pix_per_cell = [2, 4, 8]\n",
    "n = len(pix_per_cell)\n",
    "\n",
    "# Compare color spaces\n",
    "i_car = np.random.randint(n_cars)\n",
    "i_noncar = np.random.randint(n_noncars)\n",
    "car_img = cv2.imread(data_cars[i_car])\n",
    "car_img = cv2.cvtColor(car_img, cv2.COLOR_BGR2RGB)\n",
    "noncar_img = cv2.imread(data_noncars[i_noncar])\n",
    "noncar_img = cv2.cvtColor(noncar_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "f1, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "axs = axs.ravel()\n",
    "axs[0].axis('off')\n",
    "axs[0].imshow(car_img)\n",
    "axs[0].set_title('Car Sample', fontsize=20)\n",
    "axs[1].axis('off')\n",
    "axs[1].imshow(noncar_img)\n",
    "axs[1].set_title('Non-Car Sample', fontsize=20)\n",
    "\n",
    "f1.savefig(path_imgOut + 'fig2.4-1_HOGsample.png')\n",
    "\n",
    "f2, axs = plt.subplots(n, 6, figsize=(12, n*3))\n",
    "axs = axs.ravel()            \n",
    "for i in np.arange(n):\n",
    "    car_img = convert_color(car_img, color_space)\n",
    "    _, car_hog0 = get_hog_features(car_img[:,:,0], orient, pix_per_cell[i], 8, vis=True, feature_vec=True)\n",
    "    _, car_hog1 = get_hog_features(car_img[:,:,1], orient, pix_per_cell[i], 8, vis=True, feature_vec=True)\n",
    "    _, car_hog2 = get_hog_features(car_img[:,:,2], orient, pix_per_cell[i], 8, vis=True, feature_vec=True)\n",
    "    noncar_img = convert_color(noncar_img, color_space)\n",
    "    _, noncar_hog0 = get_hog_features(noncar_img[:,:,0], orient, pix_per_cell[i], 8, vis=True, feature_vec=True)\n",
    "    _, noncar_hog1 = get_hog_features(noncar_img[:,:,1], orient, pix_per_cell[i], 8, vis=True, feature_vec=True)\n",
    "    _, noncar_hog2 = get_hog_features(noncar_img[:,:,2], orient, pix_per_cell[i], 8, vis=True, feature_vec=True)\n",
    "    \n",
    "    for j in range(6):\n",
    "        axs[6*i+j].axis('off')\n",
    "        axs[6*i+j].set_title(\"\\n\".join(wrap(color_space + ', '+ re.findall('[A-Z][^A-Z]*', color_space)[j%3] + ' channel, ' + str(pix_per_cell[i]) + ' pix_per_cell', 12)))\n",
    "    axs[6*i+0].imshow(car_hog0, cmap='gray')\n",
    "    axs[6*i+1].imshow(car_hog1, cmap='gray')\n",
    "    axs[6*i+2].imshow(car_hog2, cmap='gray')\n",
    "    axs[6*i+3].imshow(noncar_hog0, cmap='gray')\n",
    "    axs[6*i+4].imshow(noncar_hog1, cmap='gray')\n",
    "    axs[6*i+5].imshow(noncar_hog2, cmap='gray')\n",
    "    \n",
    "f2.savefig(path_imgOut + 'fig2.4-2_HOGppc.png')\n",
    "    \n",
    "print(u'\\u2713', 'pix_per_cell visualized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly 2 pixels per cell performs best, but it may severely limit performance..\n",
    "# Maybe we can try things out with 4 pixels per cell for the time being\n",
    "pix_per_cell = 4\n",
    "# Next up, cells per block\n",
    "cell_per_block = [2, 4, 6, 8]\n",
    "n = len(cell_per_block)\n",
    "\n",
    "# Compare color spaces\n",
    "i_car = np.random.randint(n_cars)\n",
    "i_noncar = np.random.randint(n_noncars)\n",
    "car_img = cv2.imread(data_cars[i_car])\n",
    "car_img = cv2.cvtColor(car_img, cv2.COLOR_BGR2RGB)\n",
    "noncar_img = cv2.imread(data_noncars[i_noncar])\n",
    "noncar_img = cv2.cvtColor(noncar_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "f1, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "axs = axs.ravel()\n",
    "axs[0].axis('off')\n",
    "axs[0].imshow(car_img)\n",
    "axs[0].set_title('Car Sample', fontsize=20)\n",
    "axs[1].axis('off')\n",
    "axs[1].imshow(noncar_img)\n",
    "axs[1].set_title('Non-Car Sample', fontsize=20)\n",
    "\n",
    "f1.savefig(path_imgOut + 'fig2.5-1_HOGsample.png')\n",
    "    \n",
    "f2, axs = plt.subplots(n, 6, figsize=(12, n*3))\n",
    "axs = axs.ravel()\n",
    "    \n",
    "for i in np.arange(len(cell_per_block)):\n",
    "    car_img = convert_color(car_img, color_space)\n",
    "    _, car_hog0 = get_hog_features(car_img[:,:,0], orient, pix_per_cell, cell_per_block[i], vis=True, feature_vec=True)\n",
    "    _, car_hog1 = get_hog_features(car_img[:,:,1], orient, pix_per_cell, cell_per_block[i], vis=True, feature_vec=True)\n",
    "    _, car_hog2 = get_hog_features(car_img[:,:,2], orient, pix_per_cell, cell_per_block[i], vis=True, feature_vec=True)\n",
    "    noncar_img = convert_color(noncar_img, color_space)\n",
    "    _, noncar_hog0 = get_hog_features(noncar_img[:,:,0], orient, pix_per_cell, cell_per_block[i], vis=True, feature_vec=True)\n",
    "    _, noncar_hog1 = get_hog_features(noncar_img[:,:,1], orient, pix_per_cell, cell_per_block[i], vis=True, feature_vec=True)\n",
    "    _, noncar_hog2 = get_hog_features(noncar_img[:,:,2], orient, pix_per_cell, cell_per_block[i], vis=True, feature_vec=True)\n",
    "    \n",
    "    for j in range(6):\n",
    "        axs[6*i+j].axis('off')\n",
    "        axs[6*i+j].set_title(\"\\n\".join(wrap(color_space + ', '+ re.findall('[A-Z][^A-Z]*', color_space)[j%3] + ' channel, ' + str(cell_per_block[i]) + ' cell_per_block', 14)))\n",
    "    axs[6*i+0].imshow(car_hog0, cmap='gray')\n",
    "    axs[6*i+1].imshow(car_hog1, cmap='gray')\n",
    "    axs[6*i+2].imshow(car_hog2, cmap='gray')\n",
    "    axs[6*i+3].imshow(noncar_hog0, cmap='gray')\n",
    "    axs[6*i+4].imshow(noncar_hog1, cmap='gray')\n",
    "    axs[6*i+5].imshow(noncar_hog2, cmap='gray')\n",
    "    \n",
    "f2.savefig(path_imgOut + 'fig2.5-2_HOGcpb.png')\n",
    "    \n",
    "print(u'\\u2713', 'cell_per_block visualized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seems like 2 cells per block is sufficient\n",
    "cell_per_block = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanded Feature Extraction (includes spatial bins and color histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to compute color histogram features \n",
    "# NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                     hist_bins=32, orient=9,\n",
    "                     pix_per_cell=2, cell_per_block=2, hog_channel=0,\n",
    "                     spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)      \n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    print('features length:', len(features))\n",
    "    return features\n",
    "    \n",
    "print(u'\\u2713', \"extract_features(imgs, color_space='RGB', spatial_size=(32, 32), hist_bins=32, orient=9, pix_per_cell=2, cell_per_block=2, hog_channel=0, spatial_feat=True, hist_feat=True, hog_feat=True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set extract_feature parameters based on results\n",
    "color_space = 'YUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 12 # HOG orientations\n",
    "pix_per_cell = 4 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 32 # Number of histogram bins\n",
    "hist_range = (0,256)\n",
    "spatial_feat = False # Spatial features on or off\n",
    "hist_feat = False # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "\n",
    "if spatial_feat:\n",
    "    spatial_txt = str(spatial_size[0]) + ' by ' + str(spatial_size[1]) + ' spatial size'\n",
    "else:\n",
    "    spatial_txt = 'No spatial bin features'\n",
    "if hist_feat:\n",
    "    hist_txt = str(hist_bins) + ' histogram bins of range ' + str(hist_range[0]) + ' to ' + str(hist_range[1])\n",
    "else:\n",
    "    hist_txt = 'No color histogram features'\n",
    "if hog_feat:\n",
    "    hog_txt = hog_channel\n",
    "else:\n",
    "    hog_txt = '0'\n",
    "\n",
    "print('HOG features generated with: ', \"\\n\",\n",
    "      color_space, ' colorspace (', hog_txt, ' channel ),' \"\\n\", \n",
    "      orient, ' orientations,', \"\\n\",\n",
    "      pix_per_cell, 'pixels per cell,', \"\\n\",\n",
    "      cell_per_block, 'cells per block,', \"\\n\",\n",
    "      spatial_txt, \"\\n\", hist_txt)\n",
    "\n",
    "# Conduct feature extraction on sample data\n",
    "t0 = time.time()\n",
    "car_features = extract_features(data_cars, color_space=color_space, spatial_size=(32, 32),\n",
    "                                hist_bins=32, orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                                spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "t1 = time.time()\n",
    "print(u'\\u2713', 'car_features generated', '(' + str(round(t1 - t0, 2)) + ' seconds)')\n",
    "noncar_features = extract_features(data_noncars, color_space=color_space, spatial_size=(32, 32),\n",
    "                                hist_bins=32, orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                                spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "t2 = time.time()\n",
    "print(u'\\u2713', 'noncar_features generated', '(' + str(round(t2- t1, 2)) + ' seconds)')\n",
    "t3 = time.time()\n",
    "print('Total time:', round(t3 - t0, 2), 'seconds to extract HOG features')\n",
    "\n",
    "# Create matrix of feature vectors and vector of labels\n",
    "X = np.vstack((car_features, noncar_features)).astype(np.float64)\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(noncar_features))))\n",
    "\n",
    "# Split into Training/Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "\n",
    "print('Shape of X_train: ', X_train.shape)\n",
    "print('Shape of X_test: ', X_test.shape)\n",
    "print('Feature vector length:', len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Classifier\n",
    "* Use a linear SVC to train a classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model variables\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Train model\n",
    "t0 = time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "# Test model\n",
    "y_pred = svc.predict(X_test)\n",
    "t2 = time.time()\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "\n",
    "print(u'\\u2713', 'SVC model generated', \"\\n\",\n",
    "      'Training time:', round(t1 - t0, 2), 'seconds', \"\\n\", \n",
    "      'Testing time:', round(t2 - t1, 2), 'seconds', \"\\n\",\n",
    "      'Prediction accuracy:', round(acc, 5)*100, '%', \"\\n\",\n",
    "      'Total time elapsed:', round(t2 - t0, 2), 'seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define windows to make classification predictions\n",
    "def get_windows(img, xy_window=(64, 64), overlap=(0.3, 0), rows=2):\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    # Determine window search area\n",
    "    x_step = int((1 - overlap[0]) * xy_window[0]) # horizontal step distance from previous window\n",
    "    y_step = int((1 - overlap[1]) * xy_window[1]) # vertical step distance from previous window\n",
    "    x_mid = w // 2 # middle of the image\n",
    "    x_start = (x_mid - xy_window[0] // 2) % x_step # left-most UL rectangle point\n",
    "    x_stop = w - x_start - xy_window[0] # right-most rectangle UL point\n",
    "    y_start = 400 # top-most rectangle UL point\n",
    "    y_stop = min(y_start + y_step * (rows - 1),\n",
    "                 h - xy_window[1]) # bottom-most rectangle UL point\n",
    "    nx_wins = (x_stop - x_start) // x_step + 1\n",
    "    ny_wins = (y_stop - y_start) // y_step + 1\n",
    "    rectangles = []\n",
    "    for j in range(ny_wins):\n",
    "        y1 = j * y_step + y_start\n",
    "        y2 = y1 + xy_window[1]\n",
    "        for i in range(nx_wins):\n",
    "            x1 = i * x_step + x_start\n",
    "            x2 = x1 + xy_window[0]\n",
    "            rectangles.append(((x1, y1), (x2, y2)))\n",
    "    return rectangles\n",
    "\n",
    "print(u'\\u2713', 'get_rectangles(img, xy_window=(64, 64), overlap=(0.3, 0), rows=2)')\n",
    "\n",
    "# Define a function to draw bounding boxes\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6, color_inc=True):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    colorR = color[0]\n",
    "    colorG = color[1]\n",
    "    colorB = color[2]\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], (colorR, colorG, colorB), thick)\n",
    "        colorR = (colorR + 10) % 255\n",
    "        colorG = (colorG + 30) % 255\n",
    "        colorB = (colorB + 50) % 255\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "print(u'\\u2713', 'draw_boxes(img, bboxes, color=(0, 0, 255), thick=6, color_inc=True)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualise windows\n",
    "path_testImages = 'test_images/'\n",
    "test_images = glob.glob(path_testImages + '*.jpg')\n",
    "n_testImages = len(test_images)\n",
    "\n",
    "test_img = cv2.imread(test_images[0])\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "xy_windows = [(64, 64), (80, 80), (96, 96), (112, 112)]\n",
    "windows_all = []\n",
    "\n",
    "f, axs = plt.subplots(len(xy_windows), 1, figsize=(50, len(xy_windows) * 10))\n",
    "for w in range(len(xy_windows)):\n",
    "    windows = get_windows(test_img, xy_window=xy_windows[w])\n",
    "    boxes = draw_boxes(test_img, windows)\n",
    "    axs[w].imshow(boxes)\n",
    "    axs[w].set_title(str(xy_windows[w][0]) + ' x ' + str(xy_windows[w][1]) + ' sized windows', fontsize=24)\n",
    "    windows_all.append(windows)\n",
    "    print(str(xy_windows[w][0]) + ' x ' + str(xy_windows[w][1]) + ' sized windows:', len(windows), ' boxes')\n",
    "\n",
    "n_boxes = sum([len(windows_all[i]) for i in range(len(windows_all))])\n",
    "print(u'\\u2713', 'Total number of boxes:', n_boxes)\n",
    "\n",
    "f.savefig(path_imgOut + 'fig3.1_windows.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that can detect cars in an image\n",
    "def find_cars(img, ystart, y_end, boxes, scale, cspace, hog_channel, svc, X_scaler, orient, \n",
    "              pix_per_cell, cell_per_block, spatial_size, hist_bins, vis_rect=False):\n",
    "    \n",
    "    img = img.astype(np.float32) / 255\n",
    "    \n",
    "    # Decrease image size (reduce parameters)\n",
    "    img_tosearch = img[y_start:y_end,:,:]\n",
    "    \n",
    "    # Perform color conversion\n",
    "    if cspace != 'RGB':\n",
    "        if cspace == 'HLS':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2HLS)\n",
    "        elif cspace == 'HSV':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2HSV)\n",
    "        elif cspace == 'LUV':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2LUV)\n",
    "        elif cspace == 'YUV':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YUV)\n",
    "        elif cspace == 'YCrCb':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YCrCb)\n",
    "    else: ctrans_tosearch = np.copy(image)   \n",
    "    \n",
    "    if 0:\n",
    "        # Rescale image as defined\n",
    "        if scale != 1:\n",
    "            h, w = ctrans_tosearch.shape[0], ctrans_tosearch.shape[1]\n",
    "            ctrans_tosearch = cv2.resize(ctrans_tosearch, (32, 32))\n",
    "\n",
    "    # Colorspace channels \n",
    "    if hog_channel == 'ALL':\n",
    "        ch1 = ctrans_tosearch[:,:,0]\n",
    "        ch2 = ctrans_tosearch[:,:,1]\n",
    "        ch3 = ctrans_tosearch[:,:,2]\n",
    "    else: \n",
    "        ch1 = ctrans_tosearch[:,:,hog_channel]\n",
    "        \n",
    "    # Get the boxes that are classified as cars\n",
    "    car_boxes = []\n",
    "    for box in boxes:\n",
    "        # get box region points\n",
    "        x1, y1 = box[0][0], box[0][1] - y_start\n",
    "        x2, y2 = box[1][0], box[1][1] - y_start\n",
    "        # get hog features of region\n",
    "        hog_feat1 = get_hog_features(cv2.resize(ch1[y1:y2, x1:x2], (64,64)), orient, pix_per_cell, cell_per_block, feature_vec=False).ravel()\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_feat2 = get_hog_features(cv2.resize(ch2[y1:y2, x1:x2], (64,64)), orient, pix_per_cell, cell_per_block, feature_vec=False).ravel()\n",
    "            hog_feat3 = get_hog_features(cv2.resize(ch3[y1:y2, x1:x2], (64,64)), orient, pix_per_cell, cell_per_block, feature_vec=False).ravel()\n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3)).astype(np.float64)\n",
    "        else:\n",
    "            hog_features = hog_feat1\n",
    "        # make prediction on region\n",
    "        hog_features = hog_features.reshape(1,-1)\n",
    "        #print((x1, y1), (x2, y2), 'hog_features shape:', hog_features.shape)\n",
    "        box_pred = svc.predict(hog_features)\n",
    "        if box_pred == 1:\n",
    "            car_boxes.append(box)\n",
    "        \n",
    "    return car_boxes\n",
    "\n",
    "print(u'\\u2713', \"find_cars(img, ystart, y_end, boxes, scale, cspace, hog_channel, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, vis_rect=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def box_builder(windows):\n",
    "    boxes = []\n",
    "    for box in windows:\n",
    "        boxes += box\n",
    "    return boxes\n",
    "\n",
    "print(u'\\u2713', 'box_builder(windows)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Testing the box finder\n",
    "boxes = box_builder(windows_all)\n",
    "#test_img = mpimg.imread('test_images/test1.jpg')\n",
    "#file_img = test_images[np.random.randint(n_testImages)]\n",
    "file_img = test_images[0]\n",
    "test_img = mpimg.imread(file_img)\n",
    "\n",
    "cspace = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 12\n",
    "pix_per_cell = 4\n",
    "cell_per_block = 2\n",
    "\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 32 # Number of histogram bins\n",
    "hist_range = (0, 256)\n",
    "spatial_feat = False # Spatial features on or off\n",
    "hist_feat = False # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "\n",
    "scale = 1\n",
    "y_start = boxes[0][0][1] # 400\n",
    "y_end = boxes[n_boxes-1][1][1] # 624\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "rectangles = find_cars(test_img, y_start, y_end, boxes, scale, cspace, hog_channel, svc, X_scaler, orient, \n",
    "                       pix_per_cell, cell_per_block, spatial_size, hist_bins, vis_rect=False)\n",
    "print('# boxes detecting cars:', len(rectangles))\n",
    "\n",
    "car_img = draw_boxes(test_img, rectangles)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(car_img)\n",
    "plt.title(\"Detected cars for '\" + file_img.split('/')[1] + \"'\", fontsize=20)\n",
    "plt.savefig(path_imgOut + 'fig3.2_carsBoxes.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmapping\n",
    "* Generate heatmap image\n",
    "* Apply threshold\n",
    "* Determine bounds for detected cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a heatmap for boxes detecting a vehicle\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "    \n",
    "print(u'\\u2713', 'add_heat(heatmap, bbox_list)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_img = np.zeros_like(test_img[:,:,0])\n",
    "heat_img = add_heat(heat_img, rectangles)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(heat_img, cmap='hot')\n",
    "plt.title(\"Heatmap for '\" + file_img.split('/')[1] + \"'\", fontsize=20)\n",
    "plt.savefig(path_imgOut + 'fig4.1_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttype = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a threshold to remove false positives\n",
    "if ttype:\n",
    "    def apply_threshold(heatmap, threshold):\n",
    "        # Zero out pixels below the threshold\n",
    "        heatmap[heatmap < threshold] = 0\n",
    "        # Return thresholded map\n",
    "        return heatmap\n",
    "\n",
    "else:\n",
    "    def apply_threshold(heatmap, threshold):\n",
    "        threshmap = np.copy(heatmap)\n",
    "        labels = label(heatmap)\n",
    "        rects = []\n",
    "        for box in range(1, labels[1]+1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == box).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox)+1, np.max(nonzeroy)+1))\n",
    "            if np.max(threshmap[bbox[0][1]:bbox[1][1],bbox[0][0]:bbox[1][0]]) <= threshold:\n",
    "                labels[0][bbox[0][1]:bbox[1][1],bbox[0][0]:bbox[1][0]] = 0\n",
    "        # Return thresholded map and labels\n",
    "        labels = label(labels[0])\n",
    "        return labels\n",
    "\n",
    "print(u'\\u2713', 'apply_threshold(heatmap, threshold)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ttype:\n",
    "    thresh = 1\n",
    "    thresh_img = apply_threshold(heat_img, thresh)\n",
    "    labels = label(thresh_img)\n",
    "    print('Cars detected:', labels[1])\n",
    "else:\n",
    "    thresh = 1\n",
    "    labels = apply_threshold(heat_img, thresh)\n",
    "    thresh_img, objs = labels\n",
    "    print('Cars detected:', objs)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(thresh_img, cmap='gray')\n",
    "plt.title(\"Objects found for \" + file_img.split('/')[1] + \"' (threshold={})\".format(thresh), fontsize=20)\n",
    "plt.savefig(path_imgOut + 'fig4.2_threshmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw labeled boxes onto image\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    img_out = np.copy(img)\n",
    "    rects = []\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        rects.append(bbox)\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img_out, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img_out, rects\n",
    "\n",
    "print(u'\\u2713', 'draw_labeled_bboxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding boxes on a copy of the image\n",
    "draw_img, rect = draw_labeled_bboxes(test_img, labels)\n",
    "# Display the image\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Cars detected', fontsize=20)\n",
    "plt.savefig(path_imgOut + 'fig4.3_carsDetected.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processFrame(img):\n",
    "    # Set all parameters\n",
    "\n",
    "    color_space = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "    orient = 12 # HOG orientations\n",
    "    pix_per_cell = 4 # HOG pixels per cell\n",
    "    cell_per_block = 2 # HOG cells per block\n",
    "    hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "    spatial_size = (16, 16) # Spatial binning dimensions\n",
    "    hist_bins = 32 # Number of histogram bins\n",
    "    hist_range = (0,256)\n",
    "    spatial_feat = False # Spatial features on or off\n",
    "    hist_feat = False # Histogram features on or off\n",
    "    hog_feat = True # HOG features on or off\n",
    "\n",
    "    scale = 1\n",
    "    y_start = boxes[0][0][1] # 400\n",
    "    y_end = boxes[n_boxes-1][1][1] # 624\n",
    "    X_scaler = StandardScaler()\n",
    "\n",
    "    rectangles = find_cars(img, y_start, y_end, boxes, scale, cspace, hog_channel, svc, X_scaler, orient, \n",
    "                           pix_per_cell, cell_per_block, spatial_size, hist_bins, vis_rect=False)\n",
    "    heat_img = np.zeros_like(img[:,:,0])\n",
    "    heat_img = add_heat(heat_img, rectangles)\n",
    "\n",
    "    if ttype:\n",
    "        thresh = 2\n",
    "        threshmap = apply_threshold(heat_img, thresh)\n",
    "        labels = label(threshmap)\n",
    "    else:\n",
    "        thresh = max(max(np.unique(heat_img)) - 2, 0)\n",
    "        labels = apply_threshold(heat_img, thresh)\n",
    "    draw_img, rect = draw_labeled_bboxes(img, labels)\n",
    "\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_images = len(test_images)\n",
    "\n",
    "f, axs = plt.subplots(n_images, 4, figsize=(16, n_images*3))\n",
    "f.subplots_adjust(hspace=0.004, wspace=0.002)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, file in enumerate(test_images):\n",
    "    # original image\n",
    "    img = mpimg.imread(file)\n",
    "    axs[4*i+0].axis('off')\n",
    "    axs[4*i+0].imshow(img)\n",
    "    axs[4*i+0].set_title(file.split('/')[1].split('.')[0])\n",
    "    \n",
    "    # heatmap image\n",
    "    rectangles = find_cars(img, y_start, y_end, boxes, scale, cspace, hog_channel, svc, X_scaler, orient, \n",
    "                           pix_per_cell, cell_per_block, spatial_size, hist_bins, vis_rect=False)\n",
    "    heat_img = np.zeros_like(img[:,:,0])\n",
    "    heat_img = add_heat(heat_img, rectangles)\n",
    "    axs[4*i+1].axis('off')\n",
    "    axs[4*i+1].imshow(heat_img, cmap='hot')\n",
    "    axs[4*i+1].set_title('heatmap')\n",
    "    \n",
    "    # thresholded object map\n",
    "    if ttype:\n",
    "        threshmap = apply_threshold(heat_img, thresh)\n",
    "        labels = label(threshmap)\n",
    "        axs[4*i+2].axis('off')\n",
    "        axs[4*i+2].imshow(labels[0], cmap='gray')\n",
    "        axs[4*i+2].set_title('threshmap')\n",
    "    else:\n",
    "        thresh = max(max(np.unique(heat_img)) - 2, 0)\n",
    "        labels = apply_threshold(heat_img, thresh)\n",
    "        axs[4*i+2].axis('off')\n",
    "        axs[4*i+2].imshow(labels[0], cmap='gray')\n",
    "        axs[4*i+2].set_title('threshmap')\n",
    "    \n",
    "    # cars detected\n",
    "    draw_img, rect = draw_labeled_bboxes(img, labels)\n",
    "    axs[4*i+3].axis('off')\n",
    "    axs[4*i+3].imshow(draw_img)\n",
    "    axs[4*i+3].set_title(str(labels[1]) + ' cars detected')\n",
    "    \n",
    "plt.savefig(path_imgOut + 'fig5_imagesCarsDetected.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_file = path_vidOut + 'test_video_out.mp4'\n",
    "clip_test = VideoFileClip(path_vidIn + 'test_video.mp4')\n",
    "clip_test_out = clip_test.fl_image(processFrame)\n",
    "%time clip_test_out.write_videofile(test_out_file, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_file = path_vidOut + 'project_video_out.mp4'\n",
    "clip_test = VideoFileClip(path_vidIn + 'project_video.mp4')\n",
    "clip_test_out = clip_test.fl_image(processFrame)\n",
    "%time clip_test_out.write_videofile(test_out_file, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
